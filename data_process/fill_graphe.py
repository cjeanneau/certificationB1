import sys
import logging
from bddn4j import commune_graph_service
from data_process  import (
    get_soup,
    get_communes_limitrophes,
    get_infos_commune,
    get_commune_name)

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),  # ‚úÖ Affichage dans le terminal
        logging.FileHandler('fill_graphe.log')  # ‚úÖ Optionnel : fichier de log
    ]
)
logger = logging.getLogger(__name__)


def fill_graphe():
    
    """Initialise la base avec la commune de d√©part (Tours)"""
    logger.info("Initialisation de la base de donn√©es Neo4j...")
    commune_graph_service.clear_database()
    logger.info("Base de donn√©es Neo4j initialis√©e")
    
    # Cr√©er Tours comme commune de d√©part
    nom_tours = "Tours"
    url_tours = "https://fr.wikipedia.org/wiki/Tours"
    id_node_tours = commune_graph_service.create_temporary_commune_and_return_id(
        nom=nom_tours,
        url=url_tours,
    )
    logger.info(f"üèõÔ∏è Commune de d√©part '{nom_tours}' cr√©√©e avec l'id : {id_node_tours}")

    for iteration in range(0, 20):  # Nombre d'it√©rations √† ajuster selon les besoins
        print("======================================================")
        print("==================== It√©ration {} ====================".format(iteration + 1))
        print("======================================================")
        process_communes_not_scrapped()

def process_communes_not_scrapped():
    # on r√©cup√®re la liste des communes √† srcapper
    communes_to_be_scrapped = commune_graph_service.get_communes_not_scraped()
    
    for commune in communes_to_be_scrapped:
        logger.info(f"Commune √† scrapper : {commune['nom']} - URL : {commune['url']}")
        
        # Ici on pourrait rajouter e test de region ou departement ou pays 
        if is_region("Centre-Val de Loire", commune['url']):
            process_single_commune(commune)


def is_region(region: str, commune_url: str) -> bool:
    """V√©rifie si la commune appartient √† la r√©gion sp√©cifi√©e"""
    # Ici on pourrait impl√©menter une logique plus complexe pour v√©rifier la r√©gion
    # Par exemple, en utilisant une liste de communes connues de cette r√©gion
    # Pour l'instant, on va juste v√©rifier si le nom de la commune contient le nom de la r√©gion
    soup= get_soup(commune_url)
    if not soup:
        logger.error(f"Erreur lors de la r√©cup√©ration de la page pour {commune_url}")
        return False
    commune_info = get_infos_commune(soup)
    if not commune_info:
        logger.error(f"Erreur lors de la r√©cup√©ration des infos pour {commune_url}")
        return False
    if commune_info.get('R√©gion') == region:
        return True
    else:
        return False    

def process_single_commune(commune: dict) -> bool:
    """Traite une seule commune - retourne True si traitement r√©ussi"""
    logger.info(f"{commune['nom']} - ({commune['url']})")
    
    if not commune['url']:
        return False
        
    try:
        soup = get_soup(commune['url'])                
        infos_commune = get_infos_commune(soup)
        
    
        # Mettre √† jour la commune avec les infos scrapp√©es
        id_origin = commune_graph_service.create_commune_and_return_id(
            nom=commune['nom'],
            pays=infos_commune.get('Pays', None),
            region=infos_commune.get('R√©gion', None),
            departement=infos_commune.get('D√©partement', None),
            code_commune=infos_commune.get('Code commune', None),
            code_postaux=infos_commune.get('Code postal', None),
            url=commune['url'],
            scraped=False  # Pas encore termin√©
        )

       
        if id_origin is None:
            logger.error(f"Impossible de cr√©er/mettre √† jour la commune {commune['nom']}")
            # DEBUG: Essayer avec des valeurs par d√©faut
            logger.info(f"DEBUG: Tentative avec valeurs par d√©faut...")
            id_origin = commune_graph_service.create_commune_and_return_id(
                nom=commune['nom'],
                pays="FR",
                region="Centre-Val de Loire",
                departement="Indre-et-Loire",
                code_commune=f"TEMP_{commune['nom'].replace(' ', '_').replace('-', '_')}",
                code_postaux="37000",
                url=commune['url'],
                scraped=False
            )
            logger.info(f"DEBUG: ID avec valeurs par d√©faut: {id_origin}")
            
            if not id_origin:
                return False
        
        # Scrapper les communes limitrophes
        logger.info(f"Scrapping des communes limitrophes pour {commune['nom']}")
        communes_limitrophes = get_communes_limitrophes(soup)
        
        # Traiter les communes limitrophes
        process_commune_limitrophes(id_origin, communes_limitrophes)
        
        # Marquer la commune d'origine comme scrapp√©e
        commune_graph_service.mark_commune_as_scraped_by_id(node_id=id_origin)
        
        return True
        
    except Exception as e:
        logger.error(f"Erreur lors du traitement de {commune['nom']}: {str(e)}")
        return False

def process_commune_limitrophes(id_origin: int, communes_limitrophes: dict):
    """Traite les communes limitrophes et cr√©e les relations"""
    for direction, commune_to_register in communes_limitrophes.items():
        print(f"Orientation : {direction} : ")
        for commune_limits in commune_to_register:
            nom_comm_limit = commune_limits['nom']
            url_comm_limit = commune_limits['url']
            logger.info(f"Traitement de la commune limitrophe : {nom_comm_limit} - URL : {url_comm_limit}")
            
            id_limitrophe = None
            # V√©rifier si la commune limitrophe a un nom et une URL            
            if nom_comm_limit and url_comm_limit:
                # Cr√©er le noeud temporaire de la commune limitrophe
                # si le noeud n'existe pas
                id_limitrophe = commune_graph_service.get_commune_id_by_name_and_url(nom_comm_limit, url_comm_limit)
                if id_limitrophe is None:
                    logger.info(f"Cr√©ation de la commune limitrophe {nom_comm_limit} avec l'URL {url_comm_limit}")
                    # Cr√©er la commune limitrophe et r√©cup√©rer son ID
                    # On marque scraped √† False car on ne l'a pas encore scrapp√©e
                    id_limitrophe = commune_graph_service.create_temporary_commune_and_return_id(
                        nom=nom_comm_limit,
                        url=url_comm_limit,
                        scraped=False
                    )
            elif not url_comm_limit:
                # Chercher une commune existante par nom
                id_existing = commune_graph_service.get_commune_id_by_name(nom_comm_limit)
                if id_existing is not None:
                    id_limitrophe = id_existing
                else:
                    logger.warning(f"Pas de commune limitrophe trouv√©e pour {nom_comm_limit} dans la direction {direction}")
                    continue
            
            if id_limitrophe is not None:
                print(f"Cr√©ation de la relation entre {id_origin} et {id_limitrophe} dans la direction {direction}")
                # Cr√©er la relation
                commune_graph_service.add_relation_limitrophe_by_id(
                    node_id_origin=id_origin,
                    node_id_target=id_limitrophe,
                    direction=direction
                )
 

if "__name__" == "__main__":
       print("Pour test des fonctions)")
       # fill_graphe()
        
